{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Tensorflow_Graph_evaluations\n",
    "Description : Studying tensorlfow graph structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "crop_size=112\n",
    "\n",
    "cluster_length=16\n",
    "feature_size=8192\n",
    "nb_classes=2\n",
    "saved_path='/nobackup/leopauly/S2l/'\n",
    "\n",
    "batch_size=32\n",
    "memory_batch_size_train=266\n",
    "memory_batch_size_test=170\n",
    "next_batch_start=0\n",
    "sample_batch_size=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loading model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, 16,height,width,channel],name='x') \n",
    "y_true = tf.placeholder(tf.float32, [None, nb_classes],name='y_true')\n",
    "y_true_cls = tf.placeholder(tf.int64, [None],name='y_true_cls')\n",
    "\n",
    "model_keras = md.C3D_ucf101_training_model_tf(summary=False)\n",
    "out=model_keras(x_image)\n",
    "y_pred = tf.nn.softmax(out)\n",
    "y_pred_cls = tf.argmax(out, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start the session with logging placement.---- I\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "## Restore model weights from previously saved model\n",
    "saver = tf.train.Saver()\n",
    "saver = tf.train.import_meta_graph(os.path.join(saved_path,'activity_model.ckpt-67.meta'))\n",
    "saver.restore(sess, os.path.join(saved_path,'activity_model.ckpt-67'))\n",
    "print(\"Model restored from file: %s\" % saved_path,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in sess.graph.get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Wrting items to load in tensorrboards\n",
    "writer=tf.summary.FileWriter(\"/nobackup/leopauly/Graph_store_sim\",sess.graph)\n",
    "writer.close()\n",
    "\n",
    "print(\"===========End=================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting TensorBoard b'47' at http://0.0.0.0:6006\n",
      "(Press CTRL+C to quit)\n",
      "WARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\n",
      "WARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\n",
      "WARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\n",
      "WARNING:tensorflow:path ../external/data/plugin/text/runs not found, sending 404\n"
     ]
    }
   ],
   "source": [
    "## running tensorboard\n",
    "!tensorboard --logdir=\"/nobackup/leopauly/Graph_store_sim/\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extraction of features \n",
    "def extract_video_features(vid):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name(('flatten_2/Reshape:0')) \n",
    "    #f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 }) \n",
    "    f_v_val=np.array(sess.run([f_v], feed_dict={'conv1_input:0':vid_,'Placeholder:0':vid_ }))\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Extraction of features \n",
    "def extract_video_features_I(vid):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name(('flatten_1/Reshape:0')) \n",
    "    #f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 }) \n",
    "    f_v_val=np.array(sess.run([f_v], feed_dict={'conv1_input:0':vid_,'Placeholder:0':vid_ }))\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features\n",
    "\n",
    "## Extraction of features \n",
    "def extract_video_features_II(vid):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name(('flatten_3/Reshape:0'))\n",
    "    #f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 }) \n",
    "    f_v_val=np.array(sess.run([f_v], feed_dict={'conv1_input_2:0':vid_,'Placeholder:0':vid_ }))\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Uniform frame smapling\n",
    "def get_compress_frames_data(filename, num_frames_per_clip=16):\n",
    "  ''' Given a directory containing extracted frames, return a video clip of\n",
    "  (num_frames_per_clip) consecutive frames as a list of np arrays '''\n",
    "  ret_arr = []\n",
    "  for parent, dirnames, filenames in os.walk(filename):\n",
    "    filenames = sorted(filenames)\n",
    "    jump=math.floor((len(filenames)/num_frames_per_clip))\n",
    "    loop=0\n",
    "    for i in range(0,len(filenames),jump):\n",
    "      if (loop>15):\n",
    "        break\n",
    "      if (filenames[i].endswith('.png')):\n",
    "        image_name = str(filename) + '/' + str(filenames[i])\n",
    "        img = Image.open(image_name)\n",
    "        img_data = np.array(img)\n",
    "        ret_arr.append(img_data)\n",
    "        loop=loop+1\n",
    "  ret_arr=np.array(ret_arr)\n",
    "  #ret_arr=ret_arr/255\n",
    "  return np.array(ret_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature extraction\n",
    "\n",
    "def get_features_from_class(class_folder):\n",
    "    feature_set_a=[]\n",
    "    base_dir_a=class_folder\n",
    "    sub_dir_a=os.listdir(base_dir_a)\n",
    "    sub_dir_a=sorted(sub_dir_a)\n",
    "    if '.DS_Store' in sub_dir_a:\n",
    "        sub_dir_a.remove('.DS_Store')\n",
    "    print('\\nSubdirectories:',sub_dir_a)\n",
    "    for sub_dir_a_ in sub_dir_a:\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        feature_set_a.append(extract_video_features(vid_a))\n",
    "    return np.array(feature_set_a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def get_features_from_class_I(class_folder):\n",
    "    feature_set_a=[]\n",
    "    base_dir_a=class_folder\n",
    "    sub_dir_a=os.listdir(base_dir_a)\n",
    "    sub_dir_a=sorted(sub_dir_a)\n",
    "    if '.DS_Store' in sub_dir_a:\n",
    "        sub_dir_a.remove('.DS_Store')\n",
    "    print('\\nSubdirectories:',sub_dir_a)\n",
    "    for sub_dir_a_ in sub_dir_a:\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        feature_set_a.append(extract_video_features_I(vid_a))\n",
    "    return np.array(feature_set_a)\n",
    "\n",
    "\n",
    "def get_features_from_class_II(class_folder):\n",
    "    feature_set_a=[]\n",
    "    base_dir_a=class_folder\n",
    "    sub_dir_a=os.listdir(base_dir_a)\n",
    "    sub_dir_a=sorted(sub_dir_a)\n",
    "    print(sub_dir_a)\n",
    "    if '.DS_Store' in sub_dir_a:\n",
    "        sub_dir_a.remove('.DS_Store')\n",
    "    print('\\nSubdirectories:',sub_dir_a)\n",
    "    for sub_dir_a_ in sub_dir_a:\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        feature_set_a.append(extract_video_features_II(vid_a))\n",
    "    return np.array(feature_set_a)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_set_a_I=get_features_from_class_I('/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Push/')\n",
    "feature_set_a_II=get_features_from_class_II('/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Push/')\n",
    "print(feature_set_a_I.shape)\n",
    "print(feature_set_a_II.shape)\n",
    "print('difference',sum(sum(feature_set_a_I-feature_set_a_II)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Subdirectories: ['push_demo_0deg', 'push_demo_180deg', 'push_demo_human', 'push_robo', 'push_robo_M2', 'push_robo_M3', 'push_robo_arbview1', 'push_robo_bg_fast', 'push_robo_change_pos', 'push_robo_changetarget', 'push_robo_fast', 'push_robo_green', 'push_robo_obj2_new', 'push_robo_sideview']\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Shape [-1,16,112,112,3] has negative dimensions\n\t [[Node: conv1_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,16,112,112,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'conv1_input_1', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5c83df945a32>\", line 8, in <module>\n    saver = tf.train.import_meta_graph(os.path.join(saved_path,'activity_model.ckpt-67.meta'))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1595, in import_meta_graph\n    **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py\", line 499, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 308, in import_graph_def\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,16,112,112,3] has negative dimensions\n\t [[Node: conv1_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,16,112,112,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,16,112,112,3] has negative dimensions\n\t [[Node: conv1_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,16,112,112,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-e3e0ada0b710>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfeature_set_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_features_from_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Push/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-5e6f1fa3138e>\u001b[0m in \u001b[0;36mget_features_from_class\u001b[0;34m(class_folder)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msub_dir_a_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msub_dir_a\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mvid_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_compress_frames_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir_a\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0msub_dir_a_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mfeature_set_a\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextract_video_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvid_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature_set_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-3652497075c3>\u001b[0m in \u001b[0;36mextract_video_features\u001b[0;34m(vid)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mf_v\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tensor_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'flatten_2/Reshape:0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mf_v_val\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf_v\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'conv1_input:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvid_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'Placeholder:0'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mvid_\u001b[0m \u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_v_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Shape [-1,16,112,112,3] has negative dimensions\n\t [[Node: conv1_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,16,112,112,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n\nCaused by op 'conv1_input_1', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-3-5c83df945a32>\", line 8, in <module>\n    saver = tf.train.import_meta_graph(os.path.join(saved_path,'activity_model.ckpt-67.meta'))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1595, in import_meta_graph\n    **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/meta_graph.py\", line 499, in import_scoped_meta_graph\n    producer_op_list=producer_op_list)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/importer.py\", line 308, in import_graph_def\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Shape [-1,16,112,112,3] has negative dimensions\n\t [[Node: conv1_input_1 = Placeholder[dtype=DT_FLOAT, shape=[?,16,112,112,3], _device=\"/job:localhost/replica:0/task:0/gpu:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "feature_set_a=get_features_from_class('/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Push/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_set_b=get_features_from_class('/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_set_c=get_features_from_class('/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3,random_state=1)\n",
    "points=np.concatenate((feature_set_a,feature_set_b,feature_set_c),axis=0)\n",
    "kmeans.fit(points)\n",
    "y_km = kmeans.fit_predict(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(y_km[0:14])\n",
    "print(y_km[14:28])\n",
    "print(y_km[28:42])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Accuracy for our method\n",
    "y_true=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2]\n",
    "print('Adjusted random score:',round(metrics.adjusted_rand_score(y_true,y_km),2))\n",
    "print('Adjusted mutual infromation score:',round(metrics.adjusted_mutual_info_score(y_true,y_km),2))\n",
    "print('Homogeneity score:',round(metrics.homogeneity_score(y_true,y_km),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
