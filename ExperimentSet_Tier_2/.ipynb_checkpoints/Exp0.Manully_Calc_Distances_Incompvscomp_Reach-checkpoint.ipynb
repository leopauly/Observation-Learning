{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "Description : Studying the feature vectors in the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import xrange  \n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "import warnings\n",
    "import scipy\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "crop_size=112\n",
    "cluster_length=16\n",
    "feature_size=8192 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 2, 8, 8, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 101)               413797    \n",
      "=================================================================\n",
      "Total params: 78,409,573\n",
      "Trainable params: 78,409,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Miscellenious items finished..!!\n"
     ]
    }
   ],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, cluster_length,height,width,channel],name='x') \n",
    "model_keras = md.C3D_ucf101_training_model_tf(summary=True)\n",
    "out=model_keras(x_image)\n",
    "y_pred = tf.nn.softmax(out)\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature extraction and Distance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /nobackup/leopauly/S2l/activity_model.ckpt-67\n",
      "Model restored from file: /nobackup/leopauly/S2l/\n"
     ]
    }
   ],
   "source": [
    "## Start the session with logging placement.\n",
    "saved_path='/nobackup/leopauly/S2l/'\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "## Restore model weights from previously saved model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, os.path.join(saved_path,'activity_model.ckpt-67'))\n",
    "print(\"Model restored from file: %s\" % saved_path,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Uniform sampling of frames\n",
    "def get_compress_frames_data(filename, num_frames_per_clip=16):\n",
    "  ''' Given a directory containing extracted frames, return a video clip of\n",
    "  (num_frames_per_clip) consecutive frames as a list of np arrays '''\n",
    "  ret_arr = []\n",
    "  for parent, dirnames, filenames in os.walk(filename):\n",
    "\n",
    "    filenames = sorted(filenames)\n",
    "    jump=math.floor((len(filenames)/num_frames_per_clip))\n",
    "    loop=0\n",
    "    for i in range(0,len(filenames),jump):\n",
    "      if (loop>15):\n",
    "        break\n",
    "      if (filenames[i].endswith('.png')):\n",
    "        image_name = str(filename) + '/' + str(filenames[i])\n",
    "        img = Image.open(image_name)\n",
    "        img_data = np.array(img)\n",
    "        ret_arr.append(img_data)\n",
    "        loop=loop+1\n",
    "  ret_arr=np.array(ret_arr) #ret_arr=ret_arr/255\n",
    "  return np.array(ret_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_order=2\n",
    "def dist_calc(value_a,value_b):\n",
    "    distance_=np.linalg.norm(value_a-value_b,ord=norm_order)\n",
    "    return(distance_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extraction of features \n",
    "def extract_video_features(vid,layername):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name(layername)\n",
    "    #'flatten_1/Reshape:0' #dropout_1/cond/Merge:0 #fc8/BiasAdd:0 #Softmax:0 ('pool4/MaxPool3D:0')\n",
    "    f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_compress_frames_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ec84bd4de850>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mvid_D\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_compress_frames_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir_D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mvid_a\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_compress_frames_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mvid_b\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_compress_frames_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase_dir_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_compress_frames_data' is not defined"
     ]
    }
   ],
   "source": [
    "## Calculating distance\n",
    "\n",
    "base_dir_D='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach n Push/multi_demo_0deg'\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Incomplete multi/multi_robo_misc'\n",
    "base_dir_b='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Incomplete multi/multi_robo_incomp'\n",
    "base_dir_c='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach n Push/multi_robo_incomp'\n",
    "\n",
    "\n",
    "base_dir_d='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach n Push/multi_robo'\n",
    "\n",
    "\n",
    "vid_D=get_compress_frames_data(base_dir_D)\n",
    "vid_a=get_compress_frames_data(base_dir_a)\n",
    "vid_b=get_compress_frames_data(base_dir_b)\n",
    "vid_c=get_compress_frames_data(base_dir_c)\n",
    "vid_d=get_compress_frames_data(base_dir_d)\n",
    "\n",
    "\n",
    "vid_list=[vid_a,vid_b,vid_c,vid_d] \n",
    "for vid in vid_list:\n",
    "    feature_dist=dist_calc(extract_video_features(vid_D,'flatten_1/Reshape:0'),extract_video_features(vid,'flatten_1/Reshape:0'))\n",
    "    print(round(feature_dist,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "109.109\n",
      "81.7334\n",
      "41.2238\n",
      "94.645\n"
     ]
    }
   ],
   "source": [
    "## Calculating distance\n",
    "\n",
    "base_dir_D='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach n Push/multi_demo_0deg'\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Incomplete multi/multi_robo_misc'\n",
    "base_dir_b='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Incomplete multi/multi_robo_incomp'\n",
    "base_dir_c='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach n Push/multi_robo_incomp'\n",
    "\n",
    "base_dir_d='/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach n Push/multi_robo'\n",
    "\n",
    "\n",
    "vid_D=get_compress_frames_data(base_dir_D)\n",
    "vid_a=get_compress_frames_data(base_dir_a)\n",
    "vid_b=get_compress_frames_data(base_dir_b)\n",
    "vid_c=get_compress_frames_data(base_dir_c)\n",
    "vid_d=get_compress_frames_data(base_dir_d)\n",
    "\n",
    "\n",
    "vid_list=[vid_a,vid_b,vid_c,vid_d] \n",
    "for vid in vid_list:\n",
    "    feature_dist=dist_calc(extract_video_features(vid_D,'dropout_1/cond/Merge:0'),extract_video_features(vid,'dropout_1/cond/Merge:0'))\n",
    "    print(round(feature_dist,4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
