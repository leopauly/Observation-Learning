{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "Description : Studying the Action vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import xrange \n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import scipy.cluster.hierarchy as hcluster\n",
    "\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "crop_size=112\n",
    "cluster_length=16\n",
    "feature_size=8192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loading model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:392: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", name=\"conv1\", input_shape=(16, 112, ..., padding=\"same\")`\n",
      "  input_shape=input_shape))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:394: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool1'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:397: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", name=\"conv2\", padding=\"same\")`\n",
      "  border_mode='same', name='conv2'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:399: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool2'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:402: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv3a'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:404: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv3b'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:406: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool3'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:409: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv4a'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:411: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv4b'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:413: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool4'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:416: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv5a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv5a'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:418: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv5b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv5b'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:421: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool5\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool5'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 2, 8, 8, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 101)               413797    \n",
      "=================================================================\n",
      "Total params: 78,409,573\n",
      "Trainable params: 78,409,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Miscellenious items finished..!!\n"
     ]
    }
   ],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, cluster_length,height,width,channel],name='x') \n",
    "\n",
    "model_keras = md.C3D_ucf101_training_model_tf(summary=True)\n",
    "out=model_keras(x_image)\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting 16 frames after unifrom sampling of video sample\n",
    "def get_compress_frames_data(filename, num_frames_per_clip=16):\n",
    "  ''' Given a directory containing extracted frames, return a video clip of\n",
    "  (num_frames_per_clip) consecutive frames as a list of np arrays '''\n",
    "  ret_arr = []\n",
    "  for parent, dirnames, filenames in os.walk(filename):\n",
    "\n",
    "    filenames = sorted(filenames)\n",
    "    jump=math.floor((len(filenames)/num_frames_per_clip))\n",
    "    loop=0\n",
    "    for i in range(0,len(filenames),jump):\n",
    "      if (loop>15):\n",
    "        break\n",
    "      if (filenames[i].endswith('.png')):\n",
    "        image_name = str(filename) + '/' + str(filenames[i])\n",
    "        img = Image.open(image_name)\n",
    "        img_data = np.array(img)\n",
    "        ret_arr.append(img_data)\n",
    "        loop=loop+1\n",
    "  ret_arr=np.array(ret_arr)\n",
    "  #ret_arr=ret_arr/255\n",
    "  return np.array(ret_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature extraction\n",
    "def get_features_from_class(class_folder):\n",
    "    feature_set_a=[]\n",
    "    base_dir_a=class_folder\n",
    "    sub_dir_a=os.listdir(base_dir_a)\n",
    "    sub_dir_a=sorted(sub_dir_a)\n",
    "    print(sub_dir_a)\n",
    "    if '.DS_Store' in sub_dir_a:\n",
    "        sub_dir_a.remove('.DS_Store')\n",
    "    for sub_dir_a_ in sub_dir_a:\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        feature_set_a.append(extract_video_features(vid_a))\n",
    "    return np.array(feature_set_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /nobackup/leopauly/S2l/activity_model.ckpt-67\n",
      "Model restored from file: /nobackup/leopauly/S2l/\n"
     ]
    }
   ],
   "source": [
    "saved_path='/nobackup/leopauly/S2l/'\n",
    "## Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "## Restore model weights from previously saved model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, os.path.join(saved_path,'activity_model.ckpt-67'))\n",
    "print(\"Model restored from file: %s\" % saved_path,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extraction of features \n",
    "def extract_video_features(vid):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name('flatten_1/Reshape:0') #('flatten_1/Reshape:0') #('pool4/MaxPool3D:0') #('dropout_1/cond/Merge:0') #('fc8/BiasAdd:0') \n",
    "    f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })#f_v_val=sess.run([y_pred], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'push_demo_0deg', 'push_demo_180deg', 'push_demo_human', 'push_robo', 'push_robo_M2', 'push_robo_M3', 'push_robo_arbview1', 'push_robo_bg_fast', 'push_robo_change_pos', 'push_robo_changetarget', 'push_robo_comp0', 'push_robo_comp1', 'push_robo_comp2', 'push_robo_fast', 'push_robo_green', 'push_robo_obj2_new', 'push_robo_sideview']\n"
     ]
    }
   ],
   "source": [
    "feature_set_a=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Push/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'reach_demo_0deg', 'reach_demo_180deg', 'reach_demo_green', 'reach_human', 'reach_robo', 'reach_robo_M2', 'reach_robo_M3', 'reach_robo_arbview1', 'reach_robo_bg', 'reach_robo_change_pos', 'reach_robo_change_target', 'reach_robo_comp0', 'reach_robo_comp1', 'reach_robo_comp2', 'reach_robo_fast', 'reach_robo_obj2', 'reach_robo_sideview_new']\n"
     ]
    }
   ],
   "source": [
    "feature_set_b=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'Multi_robo_M3', 'multi_demo_0deg', 'multi_demo_180deg', 'multi_robo', 'multi_robo_M2', 'multi_robo_arbview1', 'multi_robo_bg', 'multi_robo_change_pos', 'multi_robo_change_target', 'multi_robo_comp0', 'multi_robo_comp1', 'multi_robo_comp2', 'multi_robo_fast_new', 'multi_robo_human_new', 'multi_robo_obj', 'multi_robo_obj2', 'multi_robo_sideview']\n"
     ]
    }
   ],
   "source": [
    "feature_set_c=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach n Push/')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "feature_set_d=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Incomplete/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering, Birch\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import scipy\n",
    "points=np.concatenate((feature_set_a,feature_set_b,feature_set_c),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-108-e9c3d1af3624>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-108-e9c3d1af3624>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    dn = dendrogram(Z,=600)\u001b[0m\n\u001b[0m                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "Z = linkage(points,'ward',)\n",
    "dn = dendrogram(Z,p=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 3 3 1 3 1 1 1 3 1 1 1 1]\n",
      "[1 3 1 1 1 1 3 3 1 3 3 1 1 3 1 1 3]\n",
      "[2 2 3 2 2 2 2 1 3 2 2 2 2 2 2 2 2]\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n",
      "Adjusted random score: 0.35\n",
      "Adjusted mutual infromation score: 0.393356875157\n",
      "Homogeneity score: 0.41647243658\n",
      "V measure score: 0.42\n"
     ]
    }
   ],
   "source": [
    "y_km = scipy.cluster.hierarchy.fclusterdata(points,3,criterion='maxclust',method='ward')\n",
    "\n",
    "print(y_km[0:17])\n",
    "print(y_km[17:34])\n",
    "print(y_km[34:51])\n",
    "\n",
    "## True labels\n",
    "num_test_video_per_class=17\n",
    "y_true_a=np.ones(num_test_video_per_class)*0\n",
    "y_true_b=np.ones(num_test_video_per_class)*1\n",
    "y_true_c=np.ones(num_test_video_per_class)*2\n",
    "y_true=np.concatenate((y_true_a,y_true_b,y_true_c),axis=0)\n",
    "\n",
    "print(y_true[0:17])\n",
    "print(y_true[17:34])\n",
    "print(y_true[34:51])\n",
    "\n",
    "## Results\n",
    "print('Adjusted random score:',round(metrics.adjusted_rand_score(y_true,y_km),2))\n",
    "print('Adjusted mutual infromation score:',metrics.adjusted_mutual_info_score(y_true,y_km))\n",
    "print('Homogeneity score:',metrics.homogeneity_score(y_true,y_km))\n",
    "print('V measure score:',round(metrics.v_measure_score(y_true,y_km),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.           14.           87.13724297    2.        ]\n",
      " [  35.           37.          102.20203365    2.        ]\n",
      " [  21.           31.          106.63252991    2.        ]\n",
      " [  13.           51.          136.54605328    3.        ]\n",
      " [  15.           41.          160.37473764    2.        ]\n",
      " [  44.           45.          170.6910108     2.        ]\n",
      " [  17.           53.          174.06487651    3.        ]\n",
      " [  22.           55.          184.40541056    3.        ]\n",
      " [  19.           32.          189.05071715    2.        ]\n",
      " [  12.           30.          189.20845004    2.        ]\n",
      " [   3.           20.          190.93191901    2.        ]\n",
      " [   6.           24.          192.62801399    2.        ]\n",
      " [  47.           50.          196.47663222    2.        ]\n",
      " [  38.           46.          197.75117738    2.        ]\n",
      " [  40.           48.          198.3055357     2.        ]\n",
      " [  10.           29.          198.4229356     2.        ]\n",
      " [  52.           56.          201.4075818     4.        ]\n",
      " [   4.           16.          204.47063322    2.        ]\n",
      " [  34.           49.          219.17417785    2.        ]\n",
      " [  27.           42.          220.80450337    2.        ]\n",
      " [  43.           67.          221.56565781    5.        ]\n",
      " [  65.           69.          224.90731541    4.        ]\n",
      " [  28.           66.          227.81130706    3.        ]\n",
      " [   9.           61.          228.58249969    3.        ]\n",
      " [  39.           64.          229.57649288    3.        ]\n",
      " [   5.           23.          235.93781244    2.        ]\n",
      " [  25.           59.          241.41134677    3.        ]\n",
      " [  63.           72.          244.45555995    6.        ]\n",
      " [  11.           73.          248.29577508    4.        ]\n",
      " [  54.           68.          253.65887762    5.        ]\n",
      " [  18.           33.          254.20116019    2.        ]\n",
      " [  58.           79.          267.77698186    7.        ]\n",
      " [   7.           77.          284.95555281    4.        ]\n",
      " [  36.           70.          291.0028589     3.        ]\n",
      " [   8.           26.          291.86635323    2.        ]\n",
      " [   1.           83.          299.13700392    5.        ]\n",
      " [  84.           85.          310.96259407    5.        ]\n",
      " [  75.           78.          318.92348741    9.        ]\n",
      " [   2.           74.          322.22419147    4.        ]\n",
      " [  57.           86.          325.30090044    8.        ]\n",
      " [  80.           89.          352.66103416    9.        ]\n",
      " [  81.           87.          382.01023421    7.        ]\n",
      " [  60.           76.          396.40172204    4.        ]\n",
      " [  82.           90.          409.70071721   15.        ]\n",
      " [  62.           92.          428.06198632    9.        ]\n",
      " [  91.           94.          489.39563411   24.        ]\n",
      " [  71.           88.          491.04497406   14.        ]\n",
      " [  93.           95.          510.54165651   13.        ]\n",
      " [  97.           98.          615.03669415   27.        ]\n",
      " [  96.           99.          829.53645321   51.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Predictions\n",
    "cluster_obj = AgglomerativeClustering(n_clusters=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
