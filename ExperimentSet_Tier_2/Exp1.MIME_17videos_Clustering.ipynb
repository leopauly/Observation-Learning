{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "Description : Studying the Action vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import xrange \n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "crop_size=112\n",
    "cluster_length=16\n",
    "feature_size=8192"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loading model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:451: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", name=\"conv1\", input_shape=(16, 112, ..., padding=\"same\")`\n",
      "  input_shape=input_shape))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:453: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool1'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:456: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", name=\"conv2\", padding=\"same\")`\n",
      "  border_mode='same', name='conv2'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:458: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool2'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:461: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv3a'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:463: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv3b'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:465: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool3'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:468: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv4a'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:470: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv4b'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:472: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool4'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:475: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv5a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv5a'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:477: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv5b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv5b'))\n",
      "/home/home01/cnlp/Seeing_to_Learn/Observation-Learning/ExperimentSet_Tier_2/modelling.py:480: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool5\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool5'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 2, 8, 8, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 20)                81940     \n",
      "=================================================================\n",
      "Total params: 78,077,716\n",
      "Trainable params: 78,077,716\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Miscellenious items finished..!!\n"
     ]
    }
   ],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, cluster_length,height,width,channel],name='x') \n",
    "\n",
    "model_keras = md.C3D_MIME20_training_model_tf(summary=True)\n",
    "out=model_keras(x_image)\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting 16 frames after unifrom sampling of video sample\n",
    "def get_compress_frames_data(filename, num_frames_per_clip=16):\n",
    "  ''' Given a directory containing extracted frames, return a video clip of\n",
    "  (num_frames_per_clip) consecutive frames as a list of np arrays '''\n",
    "  ret_arr = []\n",
    "  for parent, dirnames, filenames in os.walk(filename):\n",
    "\n",
    "    filenames = sorted(filenames)\n",
    "    jump=math.floor((len(filenames)/num_frames_per_clip))\n",
    "    loop=0\n",
    "    for i in range(0,len(filenames),jump):\n",
    "      if (loop>15):\n",
    "        break\n",
    "      if (filenames[i].endswith('.png')):\n",
    "        image_name = str(filename) + '/' + str(filenames[i])\n",
    "        img = Image.open(image_name)\n",
    "        img_data = np.array(img)\n",
    "        ret_arr.append(img_data)\n",
    "        loop=loop+1\n",
    "  ret_arr=np.array(ret_arr)\n",
    "  #ret_arr=ret_arr/255\n",
    "  return np.array(ret_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature extraction\n",
    "def get_features_from_class(class_folder):\n",
    "    feature_set_a=[]\n",
    "    base_dir_a=class_folder\n",
    "    sub_dir_a=os.listdir(base_dir_a)\n",
    "    sub_dir_a=sorted(sub_dir_a)\n",
    "    print(sub_dir_a)\n",
    "    if '.DS_Store' in sub_dir_a:\n",
    "        sub_dir_a.remove('.DS_Store')\n",
    "    for sub_dir_a_ in sub_dir_a:\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        feature_set_a.append(extract_video_features(vid_a))\n",
    "    return np.array(feature_set_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load model and features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_path='/nobackup/leopauly/S2l/MIME/90_10_shuffle/'\n",
    "## Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "## Restore model weights from previously saved model\n",
    "#saver = tf.train.Saver()\n",
    "#saver.restore(sess, os.path.join(saved_path,'activity_model.ckpt-155'))\n",
    "#print(\"Model restored from file: %s\" % saved_path,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extraction of features \n",
    "def extract_video_features(vid):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name('dropout_1/cond/Merge:0')  #('flatten_1/Reshape:0') #('pool4/MaxPool3D:0') #('dropout_2/cond/Merge:0') #('fc8/BiasAdd:0') \n",
    "    f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })#f_v_val=sess.run([y_pred], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'reach_demo_0deg', 'reach_demo_180deg', 'reach_demo_green', 'reach_human', 'reach_robo', 'reach_robo_M2', 'reach_robo_M3', 'reach_robo_arbview1', 'reach_robo_bg', 'reach_robo_change_pos', 'reach_robo_change_target', 'reach_robo_comp0', 'reach_robo_comp1', 'reach_robo_comp2', 'reach_robo_fast', 'reach_robo_obj2', 'reach_robo_sideview_new']\n"
     ]
    }
   ],
   "source": [
    "feature_set_a=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'push_demo_0deg', 'push_demo_180deg', 'push_demo_human', 'push_robo', 'push_robo_M2', 'push_robo_M3', 'push_robo_arbview1', 'push_robo_bg_fast', 'push_robo_change_pos', 'push_robo_changetarget', 'push_robo_comp0', 'push_robo_comp1', 'push_robo_comp2', 'push_robo_fast', 'push_robo_green', 'push_robo_obj2_new', 'push_robo_sideview']\n"
     ]
    }
   ],
   "source": [
    "feature_set_b=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Push/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'Multi_robo_M3', 'multi_demo_0deg', 'multi_demo_180deg', 'multi_robo', 'multi_robo_M2', 'multi_robo_arbview1', 'multi_robo_bg', 'multi_robo_change_pos', 'multi_robo_change_target', 'multi_robo_comp0', 'multi_robo_comp1', 'multi_robo_comp2', 'multi_robo_fast_new', 'multi_robo_human_new', 'multi_robo_obj', 'multi_robo_obj2', 'multi_robo_sideview']\n"
     ]
    }
   ],
   "source": [
    "feature_set_c=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach n Push/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.DS_Store', 'multi_robo_incomp', 'multi_robo_left', 'multi_robo_misc', 'multi_robo_out', 'multi_robo_right', 'push_robo_incomp', 'push_robo_left', 'push_robo_misc', 'push_robo_out_new', 'push_robo_right', 'reach_robo_after_target', 'reach_robo_incomp', 'reach_robo_left', 'reach_robo_out', 'reach_robo_right']\n"
     ]
    }
   ],
   "source": [
    "feature_set_d=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Incomplete/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TSNE compression\n",
    "tsne_obj = PCA(n_components=2)\n",
    "points=np.concatenate((feature_set_a,feature_set_b,feature_set_c),axis=0)\n",
    "tsne_obj.fit(points) \n",
    "\n",
    "vis_tsne_a=tsne_obj.transform(feature_set_a) \n",
    "vis_tsne_a=np.array(vis_tsne_a)\n",
    "\n",
    "vis_tsne_b=tsne_obj.transform(feature_set_b) \n",
    "vis_tsne_b=np.array(vis_tsne_b)\n",
    "\n",
    "vis_tsne_c=tsne_obj.transform(feature_set_c) \n",
    "vis_tsne_c=np.array(vis_tsne_c)\n",
    "\n",
    "#vis_tsne_d=tsne_obj.fit_transform(feature_set_d) \n",
    "#vis_tsne_d=np.array(vis_tsne_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD8CAYAAACVZ8iyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBmZmBvx/nUQPMaW5J5MAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2abc73e7dcf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Plotting\n",
    "plt.scatter(vis_tsne_a[:, 0], vis_tsne_a[:, 1])\n",
    "plt.scatter(vis_tsne_b[:, 0], vis_tsne_b[:, 1])\n",
    "plt.scatter(vis_tsne_c[:, 0], vis_tsne_c[:, 1])\n",
    "#plt.scatter(vis_tsne_d[:, 0], vis_tsne_c[:, 1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3,random_state=1)\n",
    "points=np.concatenate((feature_set_a,feature_set_b,feature_set_c),axis=0)\n",
    "y_km = kmeans.fit_predict(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 1 0 1 2 0 0 0 0 2 0 0 0 1 1]\n",
      "[0 2 1 0 1 2 0 1 2 1 2 2 0 0 0 1 1]\n",
      "[2 2 0 2 2 2 2 1 1 2 2 2 1 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(y_km[0:17])\n",
    "print(y_km[17:34])\n",
    "print(y_km[34:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "## Accuracy for our method\n",
    "num_test_video_per_class=17\n",
    "y_true_a=np.ones(num_test_video_per_class)*0\n",
    "y_true_b=np.ones(num_test_video_per_class)*1\n",
    "y_true_c=np.ones(num_test_video_per_class)*2\n",
    "y_true=np.concatenate((y_true_a,y_true_b,y_true_c),axis=0)\n",
    "print(y_true[0:17])\n",
    "print(y_true[17:34])\n",
    "print(y_true[34:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted random score: 0.1\n",
      "Adjusted mutual infromation score: 0.0930872232019\n",
      "Homogeneity score: 0.127410508164\n",
      "V measure score: 0.13\n"
     ]
    }
   ],
   "source": [
    "print('Adjusted random score:',round(metrics.adjusted_rand_score(y_true,y_km),2))\n",
    "print('Adjusted mutual infromation score:',metrics.adjusted_mutual_info_score(y_true,y_km))\n",
    "print('Homogeneity score:',metrics.homogeneity_score(y_true,y_km))\n",
    "print('V measure score:',round(metrics.v_measure_score(y_true,y_km),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering with dimentionality reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## TSNE compression\n",
    "tsne_obj = PCA(n_components=10)\n",
    "points=np.concatenate((feature_set_a,feature_set_b,feature_set_c),axis=0)\n",
    "tsne_obj.fit(points) \n",
    "\n",
    "vis_tsne_a=tsne_obj.transform(feature_set_a) \n",
    "vis_tsne_a=np.array(vis_tsne_a)\n",
    "\n",
    "vis_tsne_b=tsne_obj.transform(feature_set_b) \n",
    "vis_tsne_b=np.array(vis_tsne_b)\n",
    "\n",
    "vis_tsne_c=tsne_obj.transform(feature_set_c) \n",
    "vis_tsne_c=np.array(vis_tsne_c)\n",
    "\n",
    "#vis_tsne_d=tsne_obj.fit_transform(feature_set_d) \n",
    "#vis_tsne_d=np.array(vis_tsne_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17, 4096)\n",
      "(17, 10)\n"
     ]
    }
   ],
   "source": [
    "print(feature_set_a.shape)\n",
    "print(vis_tsne_a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3,random_state=1)\n",
    "points=np.concatenate((vis_tsne_a,vis_tsne_b,vis_tsne_c),axis=0)\n",
    "y_km = kmeans.fit_predict(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k-means++\n"
     ]
    }
   ],
   "source": [
    "print(kmeans.init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 1 0 1 1 0 0 1 0 2 0 0 0 1 1]\n",
      "[0 1 1 0 1 1 0 1 1 1 2 2 0 0 0 1 1]\n",
      "[1 1 0 1 1 0 1 1 1 2 2 2 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_km[0:17])\n",
    "print(y_km[17:34])\n",
    "print(y_km[34:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "## Accuracy for our method\n",
    "num_test_video_per_class=17\n",
    "y_true_a=np.ones(num_test_video_per_class)*0\n",
    "y_true_b=np.ones(num_test_video_per_class)*1\n",
    "y_true_c=np.ones(num_test_video_per_class)*2\n",
    "y_true=np.concatenate((y_true_a,y_true_b,y_true_c),axis=0)\n",
    "print(y_true[0:17])\n",
    "print(y_true[17:34])\n",
    "print(y_true[34:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted random score: 0.03\n",
      "Adjusted mutual infromation score: 0.0256153772901\n",
      "Homogeneity score: 0.0646375583107\n",
      "V measure score: 0.07\n"
     ]
    }
   ],
   "source": [
    "print('Adjusted random score:',round(metrics.adjusted_rand_score(y_true,y_km),2))\n",
    "print('Adjusted mutual infromation score:',metrics.adjusted_mutual_info_score(y_true,y_km))\n",
    "print('Homogeneity score:',metrics.homogeneity_score(y_true,y_km))\n",
    "print('V measure score:',round(metrics.v_measure_score(y_true,y_km),2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Accuracy for random labelling\n",
    "import random\n",
    "y_rand_label=np.random.randint(0,3,42)\n",
    "print(y_rand_label)\n",
    "print('Adjusted random score:',metrics.adjusted_rand_score(y_rand_label,y_km))\n",
    "print('Adjusted mutual infromation score:',metrics.adjusted_mutual_info_score(y_rand_label,y_km))\n",
    "print('Homogeneity score:',metrics.homogeneity_score(y_rand_label,y_km))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "points_2d=np.concatenate((vis_tsne_a,vis_tsne_b,vis_tsne_c),axis=0)\n",
    "plt.scatter(points_2d[:, 0], points_2d[:, 1], c=y_km, s=50, cmap='viridis')\n",
    "#centers = kmeans.cluster_centers_\n",
    "#plt.scatter(centers[:, 0], centers[:, 1], c='black', s=200, alpha=0.5);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
