{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "Description : Studying the Action feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import xrange \n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "from sklearn import metrics\n",
    "from sklearn.cluster import KMeans\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "crop_size=112\n",
    "\n",
    "cluster_length=16\n",
    "feature_size=8192\n",
    "nb_classes=2\n",
    "saved_path='/nobackup/leopauly/S2l/'\n",
    "\n",
    "batch_size=32\n",
    "memory_batch_size_train=266\n",
    "memory_batch_size_test=170\n",
    "next_batch_start=0\n",
    "sample_batch_size=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available GPU details:\n",
      "Tue Feb  9 15:35:53 2021       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 450.80.02    Driver Version: 450.80.02    CUDA Version: 11.0     |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                               |                      |               MIG M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00000000:05:00.0 Off |                    0 |\r\n",
      "| N/A   34C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "|   1  Tesla K80           On   | 00000000:06:00.0 Off |                    0 |\r\n",
      "| N/A   31C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\r\n",
      "|                               |                      |                  N/A |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                  |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\r\n",
      "|        ID   ID                                                   Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|  No running processes found                                                 |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "print('Available GPU details:')\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loading model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miscellenious items finished..!!\n"
     ]
    }
   ],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, 16,height,width,channel],name='x') \n",
    "y_true = tf.placeholder(tf.float32, [None, nb_classes],name='y_true')\n",
    "y_true_cls = tf.placeholder(tf.int64, [None],name='y_true_cls')\n",
    "\n",
    "model_keras = md.C3D_ucf101_training_model_tf(summary=False)\n",
    "out=model_keras(x_image)\n",
    "y_pred = tf.nn.softmax(out)\n",
    "y_pred_cls = tf.argmax(out, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Getting 16 frames after unifrom sampling of video sample\n",
    "def get_compress_frames_data(filename, num_frames_per_clip=16):\n",
    "  ''' Given a directory containing extracted frames, return a video clip of\n",
    "  (num_frames_per_clip) consecutive frames as a list of np arrays '''\n",
    "  ret_arr = []\n",
    "  for parent, dirnames, filenames in os.walk(filename):\n",
    "    filenames = sorted(filenames)\n",
    "    jump=math.floor((len(filenames)/num_frames_per_clip))\n",
    "    loop=0\n",
    "    for i in range(0,len(filenames),jump):\n",
    "      if (loop>15):\n",
    "        break\n",
    "      if (filenames[i].endswith('.png')):\n",
    "        image_name = str(filename) + '/' + str(filenames[i])\n",
    "        img = Image.open(image_name)\n",
    "        img_data = np.array(img)\n",
    "        ret_arr.append(img_data)\n",
    "        loop=loop+1\n",
    "  ret_arr=np.array(ret_arr) \n",
    "  #ret_arr=ret_arr/255\n",
    "  return np.array(ret_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer_name='dropout_2/cond/Merge:0'\n",
    "## Extraction of features \n",
    "def extract_video_features(vid):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name(layer_name) \n",
    "    #('flatten_1/Reshape:0') #('dropout_2/cond/Merge:0') #('fc8/Relu:0')\n",
    "    f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /nobackup/leopauly/S2l/activity_model.ckpt-67\n",
      "Model restored from file: /nobackup/leopauly/S2l/\n"
     ]
    }
   ],
   "source": [
    "## Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "## Restore model weights from previously saved model \n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, os.path.join(saved_path,'activity_model.ckpt-67'))\n",
    "print(\"Model restored from file: %s\" % saved_path,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature extraction\n",
    "def get_features_from_class(class_folder):\n",
    "    feature_set_a=[]\n",
    "    base_dir_a=class_folder\n",
    "    sub_dir_a=os.listdir(base_dir_a)\n",
    "    sub_dir_a=sorted(sub_dir_a)\n",
    "    if '.DS_Store' in sub_dir_a:\n",
    "        sub_dir_a.remove('.DS_Store')\n",
    "    print('\\nSub directories:\\n',sub_dir_a)\n",
    "    for sub_dir_a_ in sub_dir_a:\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        feature_set_a.append(extract_video_features(vid_a))\n",
    "    return np.array(feature_set_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sub directories:\n",
      " ['push_demo_0deg', 'push_demo_180deg', 'push_demo_human', 'push_robo', 'push_robo_M2', 'push_robo_M3', 'push_robo_arbview1', 'push_robo_bg_fast', 'push_robo_change_pos', 'push_robo_changetarget', 'push_robo_comp0', 'push_robo_comp1', 'push_robo_comp2', 'push_robo_fast', 'push_robo_green', 'push_robo_obj2_new', 'push_robo_sideview']\n"
     ]
    }
   ],
   "source": [
    "feature_set_b=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Push/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sub directories:\n",
      " ['reach_demo_0deg', 'reach_demo_180deg', 'reach_demo_green', 'reach_human', 'reach_robo', 'reach_robo_M2', 'reach_robo_M3', 'reach_robo_arbview1', 'reach_robo_bg', 'reach_robo_change_pos', 'reach_robo_change_target', 'reach_robo_comp0', 'reach_robo_comp1', 'reach_robo_comp2', 'reach_robo_fast', 'reach_robo_obj2', 'reach_robo_sideview_new']\n"
     ]
    }
   ],
   "source": [
    "feature_set_a=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sub directories:\n",
      " ['Multi_robo_M3', 'multi_demo_0deg', 'multi_demo_180deg', 'multi_robo', 'multi_robo_M2', 'multi_robo_arbview1', 'multi_robo_bg', 'multi_robo_change_pos', 'multi_robo_change_target', 'multi_robo_comp0', 'multi_robo_comp1', 'multi_robo_comp2', 'multi_robo_fast_new', 'multi_robo_human_new', 'multi_robo_obj', 'multi_robo_obj2', 'multi_robo_sideview']\n"
     ]
    }
   ],
   "source": [
    "feature_set_c=get_features_from_class('/nobackup/leopauly/S2l/Leeds_Action_Dataset_6_7_2020/Reach n Push/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## selecting features based on the indexes\n",
    "def sel_feat(org_features,select_feature_cols):\n",
    "    selected_features = [org_features[int(i)] for i in select_feature_cols]\n",
    "    return np.array(selected_features)\n",
    "\n",
    "def select_features(feature_set,select_feature_cols):\n",
    "    improve_features=[]\n",
    "    for i in range(0,len(feature_set)):\n",
    "        improve_features.append(sel_feat(feature_set[i],select_feature_cols))\n",
    "    improve_features=np.array(improve_features)\n",
    "    print('Feature selected features:',improve_features.shape)\n",
    "    return improve_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clustering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      "[ 1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
      "[ 2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.  2.]\n"
     ]
    }
   ],
   "source": [
    "## y ground truth values\n",
    "num_test_video_per_class=17\n",
    "y_true_a=np.ones(num_test_video_per_class)*0\n",
    "y_true_b=np.ones(num_test_video_per_class)*1\n",
    "y_true_c=np.ones(num_test_video_per_class)*2\n",
    "y_true=np.concatenate((y_true_a,y_true_b,y_true_c),axis=0)\n",
    "print(y_true[0:17])\n",
    "print(y_true[17:34])\n",
    "print(y_true[34:51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected feature indexes loadded from file features_to_be_selected/sel_feat_idx_dropout_2condMerge:0_0.2.txt \n",
      "\n",
      "Feature selected features: (17, 819)\n",
      "Feature selected features: (17, 819)\n",
      "Feature selected features: (17, 819)\n",
      "\n",
      "Adjusted random score: 0.14\n",
      "Adjusted mutual infromation score: 0.15\n",
      "Homogeneity score: 0.18 \n",
      "\n",
      "Selected feature indexes loadded from file features_to_be_selected/sel_feat_idx_dropout_2condMerge:0_0.4.txt \n",
      "\n",
      "Feature selected features: (17, 1638)\n",
      "Feature selected features: (17, 1638)\n",
      "Feature selected features: (17, 1638)\n",
      "\n",
      "Adjusted random score: 0.19\n",
      "Adjusted mutual infromation score: 0.19\n",
      "Homogeneity score: 0.22 \n",
      "\n",
      "Selected feature indexes loadded from file features_to_be_selected/sel_feat_idx_dropout_2condMerge:0_0.6.txt \n",
      "\n",
      "Feature selected features: (17, 2457)\n",
      "Feature selected features: (17, 2457)\n",
      "Feature selected features: (17, 2457)\n",
      "\n",
      "Adjusted random score: 0.2\n",
      "Adjusted mutual infromation score: 0.21\n",
      "Homogeneity score: 0.24 \n",
      "\n",
      "Selected feature indexes loadded from file features_to_be_selected/sel_feat_idx_dropout_2condMerge:0_0.8.txt \n",
      "\n",
      "Feature selected features: (17, 3276)\n",
      "Feature selected features: (17, 3276)\n",
      "Feature selected features: (17, 3276)\n",
      "\n",
      "Adjusted random score: 0.21\n",
      "Adjusted mutual infromation score: 0.23\n",
      "Homogeneity score: 0.26 \n",
      "\n",
      "Selected feature indexes loadded from file features_to_be_selected/sel_feat_idx_dropout_2condMerge:0_1.0.txt \n",
      "\n",
      "Feature selected features: (17, 4096)\n",
      "Feature selected features: (17, 4096)\n",
      "Feature selected features: (17, 4096)\n",
      "\n",
      "Adjusted random score: 0.19\n",
      "Adjusted mutual infromation score: 0.22\n",
      "Homogeneity score: 0.25 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Clustering based on selected percentage of features\n",
    "percentage_of_features=np.array([.2,.4,.6,.8,1])\n",
    "for percent in (percentage_of_features):\n",
    "    file_name='features_to_be_selected/'+'sel_feat_idx_'+layer_name.translate({ord('/'): None})+'_'+str(percent)+'.txt'\n",
    "    select_feature_cols=np.loadtxt(file_name)\n",
    "    print('Selected feature indexes loadded from file',file_name,'\\n')\n",
    "    \n",
    "    feature_set_a_imporv=select_features(feature_set_a,select_feature_cols)\n",
    "    feature_set_b_imporv=select_features(feature_set_b,select_feature_cols)\n",
    "    feature_set_c_imporv=select_features(feature_set_c,select_feature_cols)\n",
    "\n",
    "    kmeans = KMeans(n_clusters=3,random_state=1)\n",
    "    points=np.concatenate((feature_set_a_imporv,feature_set_b_imporv,feature_set_c_imporv),axis=0)\n",
    "    y_km = kmeans.fit_predict(points)\n",
    "\n",
    "    ## Clustering evaluation metrics\n",
    "    print('\\nAdjusted random score:',round(metrics.adjusted_rand_score(y_true,y_km),2))\n",
    "    print('Adjusted mutual infromation score:',round(metrics.adjusted_mutual_info_score(y_true,y_km),2))\n",
    "    print('Homogeneity score:',round(metrics.homogeneity_score(y_true,y_km),2),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
