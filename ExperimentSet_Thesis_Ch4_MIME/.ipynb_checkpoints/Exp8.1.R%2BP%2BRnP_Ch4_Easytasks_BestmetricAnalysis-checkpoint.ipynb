{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "Description : Studying the feature vectors in the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import xrange  \n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import sklearn\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "import warnings\n",
    "import scipy\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "crop_size=112\n",
    "\n",
    "cluster_length=16\n",
    "feature_size=8192 \n",
    "nb_classes=2\n",
    "saved_path='/nobackup/leopauly/S2l/MIME/90_10_shuffle/'\n",
    "\n",
    "batch_size=32\n",
    "memory_batch_size_train=266\n",
    "memory_batch_size_test=170\n",
    "next_batch_start=0\n",
    "sample_batch_size=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loading model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 2, 8, 8, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 101)               413797    \n",
      "=================================================================\n",
      "Total params: 78,409,573\n",
      "Trainable params: 78,409,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Miscellenious items finished..!!\n"
     ]
    }
   ],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, 16,height,width,channel],name='x') \n",
    "y_true = tf.placeholder(tf.float32, [None, nb_classes],name='y_true')\n",
    "y_true_cls = tf.placeholder(tf.int64, [None],name='y_true_cls')\n",
    "\n",
    "model_keras = md.C3D_MIME20_training_model_tf(summary=True)\n",
    "out=model_keras(x_image)\n",
    "y_pred = tf.nn.softmax(out)\n",
    "y_pred_cls = tf.argmax(out, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature extraction and Distance calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /nobackup/leopauly/S2l/MIME/90_10_shuffle/activity_model.ckpt-155\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Assign requires shapes of both tensors to match. lhs shape= [101] rhs shape= [20]\n\t [[Node: save/Assign_20 = Assign[T=DT_FLOAT, _class=[\"loc:@fc8/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc8/bias, save/RestoreV2_20/_1)]]\n\nCaused by op 'save/Assign_20', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-9e2273cbe576>\", line 7, in <module>\n    saver = tf.train.Saver()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\n    self.build()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [101] rhs shape= [20]\n\t [[Node: save/Assign_20 = Assign[T=DT_FLOAT, _class=[\"loc:@fc8/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc8/bias, save/RestoreV2_20/_1)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1038\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1040\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1020\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1021\u001b[0;31m                                  status, run_metadata)\n\u001b[0m\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36mraise_exception_on_not_ok_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    465\u001b[0m           \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpywrap_tensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 466\u001b[0;31m           pywrap_tensorflow.TF_GetCode(status))\n\u001b[0m\u001b[1;32m    467\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [101] rhs shape= [20]\n\t [[Node: save/Assign_20 = Assign[T=DT_FLOAT, _class=[\"loc:@fc8/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc8/bias, save/RestoreV2_20/_1)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-9e2273cbe576>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m## Restore model weights from previously saved model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msaver\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'activity_model.ckpt-155'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model restored from file: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msaved_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\u001b[0m in \u001b[0;36mrestore\u001b[0;34m(self, sess, save_path)\u001b[0m\n\u001b[1;32m   1455\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Restoring parameters from %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1456\u001b[0m     sess.run(self.saver_def.restore_op_name,\n\u001b[0;32m-> 1457\u001b[0;31m              {self.saver_def.filename_tensor_name: save_path})\n\u001b[0m\u001b[1;32m   1458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1459\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    776\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    777\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 778\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    779\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m--> 982\u001b[0;31m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[1;32m    983\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1030\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1031\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[0;32m-> 1032\u001b[0;31m                            target_list, options, run_metadata)\n\u001b[0m\u001b[1;32m   1033\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1050\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1051\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1052\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1053\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Assign requires shapes of both tensors to match. lhs shape= [101] rhs shape= [20]\n\t [[Node: save/Assign_20 = Assign[T=DT_FLOAT, _class=[\"loc:@fc8/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc8/bias, save/RestoreV2_20/_1)]]\n\nCaused by op 'save/Assign_20', defined at:\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/opt/conda/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/opt/conda/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/opt/conda/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2717, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2821, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/opt/conda/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2881, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-4-9e2273cbe576>\", line 7, in <module>\n    saver = tf.train.Saver()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1056, in __init__\n    self.build()\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 1086, in build\n    restore_sequentially=self._restore_sequentially)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 691, in build\n    restore_sequentially, reshape)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 419, in _AddRestoreOps\n    assign_ops.append(saveable.restore(tensors, shapes))\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/training/saver.py\", line 155, in restore\n    self.op.get_shape().is_fully_defined())\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/state_ops.py\", line 270, in assign\n    validate_shape=validate_shape)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/gen_state_ops.py\", line 47, in assign\n    use_locking=use_locking, name=name)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 768, in apply_op\n    op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 2336, in create_op\n    original_op=self._default_original_op, op_def=op_def)\n  File \"/opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1228, in __init__\n    self._traceback = _extract_stack()\n\nInvalidArgumentError (see above for traceback): Assign requires shapes of both tensors to match. lhs shape= [101] rhs shape= [20]\n\t [[Node: save/Assign_20 = Assign[T=DT_FLOAT, _class=[\"loc:@fc8/bias\"], use_locking=true, validate_shape=true, _device=\"/job:localhost/replica:0/task:0/gpu:0\"](fc8/bias, save/RestoreV2_20/_1)]]\n"
     ]
    }
   ],
   "source": [
    "## Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "## Restore model weights from previously saved model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, os.path.join(saved_path,'activity_model.ckpt-155'))\n",
    "print(\"Model restored from file: %s\" % saved_path,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Uniform sampling of frames\n",
    "def get_compress_frames_data(filename, num_frames_per_clip=16):\n",
    "  ''' Given a directory containing extracted frames, return a video clip of\n",
    "  (num_frames_per_clip) consecutive frames as a list of np arrays '''\n",
    "  ret_arr = []\n",
    "  for parent, dirnames, filenames in os.walk(filename):\n",
    "\n",
    "    filenames = sorted(filenames)\n",
    "    jump=math.floor((len(filenames)/num_frames_per_clip))\n",
    "    loop=0\n",
    "    for i in range(0,len(filenames),jump):\n",
    "      if (loop>15):\n",
    "        break\n",
    "      if (filenames[i].endswith('.png')):\n",
    "        image_name = str(filename) + '/' + str(filenames[i])\n",
    "        img = Image.open(image_name)\n",
    "        img_data = np.array(img)\n",
    "        ret_arr.append(img_data)\n",
    "        loop=loop+1\n",
    "  ret_arr=np.array(ret_arr) #ret_arr=ret_arr/255\n",
    "  return np.array(ret_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "norm_order=.05\n",
    "def dist_calc(value_a,value_b):\n",
    "    #distance_=np.linalg.norm(value_a-value_b,ord=norm_order)\n",
    "    #distance_=scipy.spatial.distance.cosine(value_a,value_b)\n",
    "    distance_=sklearn.metrics.pairwise.cosine_similarity(value_a,value_b)\n",
    "    return(distance_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extraction of features \n",
    "def extract_video_features(vid):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name('flatten_1/Reshape:0') \n",
    "    #'flatten_1/Reshape:0' #dropout_1/cond/Merge:0 #fc8/BiasAdd:0 #Softmax:0\n",
    "    f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISTANCE CALCULATION\n",
    "\n",
    "dist_sim_class=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "print('Sub directories:',sub_dir_a)\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "print('\\nSub directories:',sub_dir_b)\n",
    "\n",
    "## Calculating Distances\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        #print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            if(sub_dir_a_!=sub_dir_b_):\n",
    "                #print(sub_dir_b_)\n",
    "                vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "                feature_dist=dist_calc(extract_video_features(vid_a),extract_video_features(vid_b))\n",
    "                dist_sim_class.append(feature_dist)\n",
    "\n",
    "            \n",
    "## Calculating intra-class variance\n",
    "dist_sim_class_nozero=dist_sim_class\n",
    "intra_var_class=sum(dist_sim_class_nozero)/len(dist_sim_class_nozero)\n",
    "print('\\nInter class variance bw class :',intra_var_class)\n",
    "print('Number of combinations:',np.shape(dist_sim_class_nozero))\n",
    "\n",
    "intra_reach=intra_var_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "print('Sub directories:',sub_dir_a)\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "print('\\nSub directories:',sub_dir_b)\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        #print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            #print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=dist_calc(extract_video_features(vid_a),extract_video_features(vid_b))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('\\nInter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Number of combinations:',np.array(dist_dif).shape)\n",
    "\n",
    "inter1_reach=inter_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach_n_Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "print('Sub directories:',sub_dir_a)\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "print('\\nSub directories:',sub_dir_b)\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        #print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            #print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=dist_calc(extract_video_features(vid_a),extract_video_features(vid_b))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('\\nInter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Number of combinations:',np.array(dist_dif).shape)\n",
    "\n",
    "inter2_reach=inter_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "print('Sub directories:',sub_dir_a)\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "print('\\nSub directories:',sub_dir_b)\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        #print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            #print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=dist_calc(extract_video_features(vid_a),extract_video_features(vid_b))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('\\nInter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Number of combinations:',np.array(dist_dif).shape)\n",
    "\n",
    "inter1_push=inter_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISTANCE CALCULATION\n",
    "\n",
    "dist_sim_class=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "print('Sub directories:',sub_dir_a)\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "print('\\nSub directories:',sub_dir_b)\n",
    "\n",
    "## Calculating Distances\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        #print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            if(sub_dir_a_!=sub_dir_b_):\n",
    "                #print(sub_dir_b_)\n",
    "                vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "                feature_dist=dist_calc(extract_video_features(vid_a),extract_video_features(vid_b))\n",
    "                dist_sim_class.append(feature_dist)\n",
    "\n",
    "            \n",
    "## Calculating intra-class variance\n",
    "dist_sim_class_nozero=dist_sim_class\n",
    "intra_var_class=sum(dist_sim_class_nozero)/len(dist_sim_class_nozero)\n",
    "print('\\nInter class variance bw class :',intra_var_class)\n",
    "print('Number of combinations:',np.shape(dist_sim_class_nozero))\n",
    "\n",
    "intra_push=intra_var_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach_n_Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "print('Sub directories:',sub_dir_a)\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "print('\\nSub directories:',sub_dir_b)\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        #print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            #print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=dist_calc(extract_video_features(vid_a),extract_video_features(vid_b))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('\\nInter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Number of combinations:',np.array(dist_dif).shape)\n",
    "\n",
    "inter2_push=inter_var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Push n Reach "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach_n_Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        #print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            #print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=dist_calc(extract_video_features(vid_a),extract_video_features(vid_b))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('Inter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Shape',np.array(dist_dif).shape)\n",
    "\n",
    "inter1_rnp=inter_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach_n_Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        #print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            #print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=dist_calc(extract_video_features(vid_a),extract_video_features(vid_b))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('Inter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Shape',np.array(dist_dif).shape)\n",
    "\n",
    "inter2_rnp=inter_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISTANCE CALCULATION\n",
    "\n",
    "dist_sim_class=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach_n_Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Exp.A.1._Easytasks/Reach_n_Push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "## Calculating Distances\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        #print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            if(sub_dir_a_!=sub_dir_b_):\n",
    "                #print(sub_dir_b_)\n",
    "                vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "                feature_dist=dist_calc(extract_video_features(vid_a),extract_video_features(vid_b))\n",
    "                dist_sim_class.append(feature_dist)\n",
    "\n",
    "            \n",
    "## Calculating intra-class variance\n",
    "dist_sim_class_nozero=dist_sim_class\n",
    "intra_var_class=sum(dist_sim_class_nozero)/len(dist_sim_class_nozero)\n",
    "print('Inter class variance bw class :',intra_var_class)\n",
    "\n",
    "\n",
    "intra_rnp=intra_var_class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ratios\n",
    "ratio1_reach=round(intra_reach/intra_reach,2)\n",
    "ratio2_reach=round(intra_reach/inter1_reach,2)\n",
    "ratio3_reach=round(intra_reach/inter2_reach,2)\n",
    "\n",
    "print('---',ratio1_reach)\n",
    "print(ratio2_reach)\n",
    "print(ratio3_reach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ratios\n",
    "ratio1_push=round(intra_push/inter1_push,2)\n",
    "ratio2_push=round(intra_push/intra_push,2)\n",
    "ratio3_push=round(intra_push/inter2_push,2)\n",
    "\n",
    "print(ratio1_push)\n",
    "print('---',ratio2_push)\n",
    "print(ratio3_push)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Ratios\n",
    "ratio1_rnp=round(intra_rnp/inter1_rnp,2)\n",
    "ratio2_rnp=round(intra_rnp/inter2_rnp,2)\n",
    "ratio3_rnp=round(intra_rnp/intra_rnp,2)\n",
    "\n",
    "print(ratio1_rnp)\n",
    "print(ratio2_rnp)\n",
    "print('---',ratio3_rnp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_overlap_ratio=round(((ratio2_reach+ratio3_reach+ratio1_push+ratio3_push+ratio1_rnp+ratio2_rnp)/6),2)\n",
    "print(class_overlap_ratio)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
