{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Experiment5_LeedsDataset_Alltasks\n",
    "Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "Description : Studying the feature vectors in the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from six.moves import xrange  # pylint: disable=redefined-builtin\n",
    "import PIL.Image as Image\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from skimage import io\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "crop_size=112\n",
    "\n",
    "cluster_length=16\n",
    "feature_size=8192 #4608 #   #16384  #487\n",
    "nb_classes=2\n",
    "saved_path='/nobackup/leopauly/S2l/'\n",
    "\n",
    "batch_size=32\n",
    "memory_batch_size_train=266\n",
    "memory_batch_size_test=170\n",
    "next_batch_start=0\n",
    "sample_batch_size=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Loading model and functions for calculating distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, 16,height,width,channel],name='x') \n",
    "y_true = tf.placeholder(tf.float32, [None, nb_classes],name='y_true')\n",
    "y_true_cls = tf.placeholder(tf.int64, [None],name='y_true_cls')\n",
    "\n",
    "model_keras = md.C3D_ucf101_training_model_tf(summary=True)\n",
    "out=model_keras(x_image)\n",
    "y_pred = tf.nn.softmax(out)\n",
    "y_pred_cls = tf.argmax(out, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "## Restore model weights from previously saved model\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, os.path.join(saved_path,'activity_model.ckpt-67'))\n",
    "print(\"Model restored from file: %s\" % saved_path,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_compress_frames_data(filename, num_frames_per_clip=16):\n",
    "  ''' Given a directory containing extracted frames, return a video clip of\n",
    "  (num_frames_per_clip) consecutive frames as a list of np arrays '''\n",
    "  ret_arr = []\n",
    "  for parent, dirnames, filenames in os.walk(filename):\n",
    "\n",
    "    filenames = sorted(filenames)\n",
    "    jump=math.floor((len(filenames)/num_frames_per_clip))\n",
    "    loop=0\n",
    "    for i in range(0,len(filenames),jump):\n",
    "      if (loop>15):\n",
    "        break\n",
    "      if (filenames[i].endswith('.png')):\n",
    "        #print(str(filename) + '/' + str(filenames[i]))\n",
    "        image_name = str(filename) + '/' + str(filenames[i])\n",
    "        img = Image.open(image_name)\n",
    "        img_data = np.array(img)\n",
    "        ret_arr.append(img_data)\n",
    "        loop=loop+1\n",
    "  ret_arr=np.array(ret_arr)\n",
    "  #ret_arr=ret_arr/255\n",
    "  return np.array(ret_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extraction of features \n",
    "def extract_video_features(vid):\n",
    "    vid_=vid.reshape(-1,cluster_length,height,width,channel)\n",
    "    f_v = sess.graph.get_tensor_by_name('flatten_1/Reshape:0')  #('dropout_2/cond/Merge:0')  #\n",
    "    f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid_,x_image:vid_,K.learning_phase(): 0 })\n",
    "    features=np.reshape(f_v_val,(-1))\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Feature extraction from each class\n",
    "def get_features_from_class(class_folder):\n",
    "    feature_set_a=[]\n",
    "    base_dir_a=class_folder\n",
    "    sub_dir_a=os.listdir(base_dir_a)\n",
    "    sub_dir_a=sorted(sub_dir_a)\n",
    "    print(sub_dir_a)\n",
    "    if '.DS_Store' in sub_dir_a:\n",
    "        sub_dir_a.remove('.DS_Store')\n",
    "    for sub_dir_a_ in sub_dir_a:\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        feature_set_a.append(extract_video_features(vid_a))\n",
    "    return np.array(feature_set_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_set_a=get_features_from_class('/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Push/')\n",
    "feature_set_b=get_features_from_class('/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach/')\n",
    "feature_set_c=get_features_from_class('/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/')\n",
    "features_all=np.concatenate((feature_set_a,feature_set_b,feature_set_c),axis=0)\n",
    "feature_labels_true=[0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,1,1,1,1,1,1,1,1,1,1,1,1,1,2,2,2,2,2,2,2,2,2,2,2,2,2,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecting top k features\n",
    "from sklearn.feature_selection import f_classif, chi2, mutual_info_classif\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "selector= SelectKBest(f_classif, k=100)\n",
    "selector.fit_transform(features_all,feature_labels_true)\n",
    "select_feature_cols = selector.get_support(indices=True)\n",
    "print(select_feature_cols)\n",
    "\n",
    "def sel_feat(org_features):\n",
    "    selected_features = [org_features[i] for i in select_feature_cols]\n",
    "    return np.array(selected_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Feature extraction and claculating distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## DISTANCE CALCULATION\n",
    "\n",
    "dist_sim_class=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "## Calculating Distances\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=np.linalg.norm(sel_feat(extract_video_features(vid_a))-sel_feat(extract_video_features(vid_b)))\n",
    "            dist_sim_class.append(feature_dist)\n",
    "\n",
    "            \n",
    "## Calculating intra-class variance\n",
    "dist_sim_class_nozero=[x for x in dist_sim_class if x!=0]\n",
    "intra_var_class=sum(dist_sim_class_nozero)/len(dist_sim_class_nozero)\n",
    "print('Inter class variance bw class :',intra_var_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=np.linalg.norm(sel_feat(extract_video_features(vid_a))-sel_feat(extract_video_features(vid_b)))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('Inter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Shape',np.array(dist_dif).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=np.linalg.norm(sel_feat(extract_video_features(vid_a))-sel_feat(extract_video_features(vid_b)))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('Inter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Shape',np.array(dist_dif).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Incomplete push/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=np.linalg.norm(sel_feat(extract_video_features(vid_a))-sel_feat(extract_video_features(vid_b)))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('Inter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Shape',np.array(dist_dif).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Incomplete_reach/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=np.linalg.norm(sel_feat(extract_video_features(vid_a))-sel_feat(extract_video_features(vid_b)))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('Inter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Shape',np.array(dist_dif).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Incomplete multi/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=np.linalg.norm(sel_feat(extract_video_features(vid_a))-sel_feat(extract_video_features(vid_b)))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('Inter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Shape',np.array(dist_dif).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Calculating distance\n",
    "\n",
    "dist_dif=[]\n",
    "\n",
    "base_dir_a='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Reach n Push/'\n",
    "sub_dir_a=os.listdir(base_dir_a)\n",
    "sub_dir_a=sorted(sub_dir_a)\n",
    "print(sub_dir_a)\n",
    "if '.DS_Store' in sub_dir_a:\n",
    "    sub_dir_a.remove('.DS_Store')\n",
    "\n",
    "base_dir_b='/nobackup/leopauly/S2l/Dataset/Leeds_Dataset_ Only_tasks_CompvsIncomp/Incomplete/'\n",
    "sub_dir_b=os.listdir(base_dir_b)\n",
    "sub_dir_b=sorted(sub_dir_b)\n",
    "print(sub_dir_b)\n",
    "if '.DS_Store' in sub_dir_b:\n",
    "    sub_dir_b.remove('.DS_Store')\n",
    "\n",
    "for sub_dir_a_ in sub_dir_a:\n",
    "        print(sub_dir_a_)\n",
    "        vid_a=get_compress_frames_data(base_dir_a+sub_dir_a_)\n",
    "        \n",
    "        for sub_dir_b_ in sub_dir_b:\n",
    "            print(sub_dir_b_)\n",
    "            vid_b=get_compress_frames_data(base_dir_b+sub_dir_b_)\n",
    "            feature_dist=np.linalg.norm(sel_feat(extract_video_features(vid_a))-sel_feat(extract_video_features(vid_b)))\n",
    "            dist_dif.append(feature_dist)\n",
    "\n",
    "\n",
    "## Calculating inter-class variance\n",
    "inter_var=sum(dist_dif)/len(dist_dif)\n",
    "print('Inter class variance bw class 1 and class 2:',inter_var)\n",
    "print('Shape',np.array(dist_dif).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
