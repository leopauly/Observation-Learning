{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2. C3D+ucf_model_training_multigpu_training\n",
    "# Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "# Description : Training the C3D model using UCF 101 action recognition dataset- Testing Phase\n",
    "\n",
    "print('Started running the program..!',flush=True)\n",
    "## Imports\n",
    "from keras.models import Sequential\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from scipy.ndimage import imread\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "import datetime\n",
    "import time\n",
    "import os \n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md\n",
    "#from DataSet.DataSet import DataSet\n",
    "import dataset as dset\n",
    "import ucf101_dataset as ucf\n",
    "\n",
    "print('Loaded libraries...!!',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "cluster_length=16\n",
    "nb_classes=101\n",
    "\n",
    "lr_rate=.001\n",
    "next_batch_start=0\n",
    "batch_size=8\n",
    "batch_size_test=16\n",
    "total_train_videos=9991\n",
    "memory_batch_size_train=50\n",
    "memory_batch_size_test=3329\n",
    "iterations= 10 # (int(total_train_videos/memory_batch_size_train)) #10001\n",
    "custom_global_step=0\n",
    "LOG_DIR='/nobackup/leopauly/logdir'\n",
    "saved_path='/nobackup/leopauly/logdirk80_2'\n",
    "\n",
    "print('Finished defining variables..!!',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, 16,height,width,channel],name='x') \n",
    "y_true = tf.placeholder(tf.float32, [None, nb_classes],name='y_true')\n",
    "y_true_cls = tf.placeholder(tf.int64, [None],name='y_true_cls')\n",
    "\n",
    "model_keras = md.C3D_ucf101_training_model_tf(summary=False)\n",
    "out=model_keras(x_image)\n",
    "y_pred = tf.nn.softmax(out)\n",
    "y_pred_cls = tf.argmax(out, dimension=1)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Training & testing\n",
    "def testing(iterations,loops):\n",
    "    #print(test_images.shape)\n",
    "    #print(test_labels_cls)\n",
    "    test_score=0\n",
    "    for j in range(int(memory_batch_size_test/batch_size_test)-1):\n",
    "        test_score_= sess.run([accuracy], feed_dict={x_image:test_images[(batch_size_test*j):(batch_size_test*(j+1))],y_true_cls:test_labels_cls[(batch_size_test*j):(batch_size_test*(j+1))],K.learning_phase(): 0 })\n",
    "        #print('returned value',test_score_)\n",
    "        print(test_score_)\n",
    "        test_score=test_score+sum(test_score_)\n",
    "    print('Test accuracy after iteration:',iterations,',loop:',loops,'is:',test_score/(j+1),flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Loading Testing data\n",
    "start_time = time.time()\n",
    "test_images, test_labels_cls, next_batch_start, _ = ucf.read_vid_and_label('./UCF101_data_preparation/test.list',memory_batch_size_test,-1,16,112,normalisation=True)\n",
    "end_time = time.time()\n",
    "time_dif = end_time - start_time\n",
    "print(\"Time usage for loading training dataset: \" + str(timedelta(seconds=int(round(time_dif)))),flush=True)\n",
    "test_labels=keras.utils.to_categorical(test_labels_cls, num_classes=nb_classes)\n",
    "print('testing data loaded',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "# Restore model weights from previously saved model\n",
    "\n",
    "#saver = tf.train.import_meta_graph(os.path.join(saved_path,'activity_model_1.ckpt-43.meta'))\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, os.path.join(saved_path,'activity_model_1.ckpt-84'))\n",
    "print(\"Model restored from file: %s\" % saved_path,flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "testing(0,0)\n",
    "end_time = time.time()\n",
    "time_dif = end_time - start_time\n",
    "print(\"Time taken for testing: \" + str(timedelta(seconds=int(round(time_dif)))),flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([n.name for n in tf.get_default_graph().as_graph_def().node])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for op in tf.get_default_graph().get_operations():\n",
    "    print(op.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.contrib.graph_editor.get_tensors(tf.get_default_graph()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "j=1\n",
    "batch_size_test=10\n",
    "vid, test_labels_cls, next_batch_start, _ = ucf.read_vid_and_label('./UCF101_data_preparation/test.list',1,-1,16,112,normalisation=True)\n",
    "test_labels=keras.utils.to_categorical(test_labels_cls, num_classes=nb_classes)\n",
    "\n",
    "f_v = sess.graph.get_tensor_by_name('pool5/MaxPool3D:0')\n",
    "print(f_v)\n",
    "#f_v_val=sess.run([f_v,accuracy], feed_dict={'conv1_input:0':test_images[(batch_size_test*j):(batch_size_test*(j+1))],y_true:test_labels[(batch_size_test*j):(batch_size_test*(j+1))],x_image:test_images[(batch_size_test*j):(batch_size_test*(j+1))],'y_true_cls:0':test_labels_cls[(batch_size_test*j):(batch_size_test*(j+1))],K.learning_phase(): 0 })\n",
    "f_v_val=sess.run([f_v], feed_dict={'conv1_input:0':vid,y_true:test_labels,x_image:vid,'y_true_cls:0':test_labels_cls,K.learning_phase(): 0 })\n",
    "print(np.array(f_v_val).shape)\n",
    "print(f_v_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_v_ = sess.graph.get_tensor_by_name('flatten_1/Reshape:0')\n",
    "print(f_v_)\n",
    "temp_=2\n",
    "#f_v_val=sess.run([f_v,accuracy], feed_dict={'conv1_input:0':test_images[(batch_size_test*j):(batch_size_test*(j+1))],y_true:test_labels[(batch_size_test*j):(batch_size_test*(j+1))],x_image:test_images[(batch_size_test*j):(batch_size_test*(j+1))],'y_true_cls:0':test_labels_cls[(batch_size_test*j):(batch_size_test*(j+1))],K.learning_phase(): 0 })\n",
    "f_v_val_=sess.run([f_v_], feed_dict={'conv1_input:0':vid,x_image:vid,K.learning_phase(): 0 })\n",
    "print(np.array(f_v_val_).shape)\n",
    "print(f_v_val_)\n",
    "\n",
    "temp=np.mean((np.array(f_v_val_))-np.mean(np.array(f_v_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=np.reshape(f_v_val_,(-1))\n",
    "print(feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(int(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
