{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Started running the program..!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded libraries...!!\n"
     ]
    }
   ],
   "source": [
    "### 2. C3D+ucf_model_training_multigpu\n",
    "# Author : @leopauly | cnlp@leeds.ac.uk <br>\n",
    "# Description : Training the C3D model using UCF 101 action recognition dataset\n",
    "\n",
    "print('Started running the program..!',flush=True)\n",
    "## Imports\n",
    "from keras.models import Sequential\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from os import listdir\n",
    "from scipy.ndimage import imread\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from keras import backend as K\n",
    "import datetime\n",
    "import time\n",
    "import os \n",
    "from datetime import timedelta\n",
    "\n",
    "# Custom scripts\n",
    "import lscript as lsp\n",
    "import modelling as md\n",
    "#from DataSet.DataSet import DataSet\n",
    "import dataset as dset\n",
    "import ucf101_dataset as ucf\n",
    "\n",
    "print('Loaded libraries...!!',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished defining variables..!!\n"
     ]
    }
   ],
   "source": [
    "height=112 \n",
    "width=112 \n",
    "channel=3\n",
    "cluster_length=16\n",
    "nb_classes=101\n",
    "\n",
    "lr_rate=.001\n",
    "next_batch_start=0\n",
    "batch_size=8\n",
    "batch_size_test=8\n",
    "total_train_videos=9991\n",
    "memory_batch_size_train=50\n",
    "memory_batch_size_test=300\n",
    "iterations= 10 # (int(total_train_videos/memory_batch_size_train)) #10001\n",
    "custom_global_step=0\n",
    "LOG_DIR='/nobackup/leopauly/logdir'\n",
    "\n",
    "print('Finished defining variables..!!',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU nodes found: 1\n",
      "Avaialble gpu: /gpu:0\n",
      "CPU nodes found: 1\n",
      "Avaialble cpu: /cpu:0\n",
      "Finished obtaining gpu details and place holders\n"
     ]
    }
   ],
   "source": [
    "## Finding how many devices are available\n",
    "gpus = [x.name for x in device_lib.list_local_devices() if x.device_type == 'GPU']\n",
    "num_gpus = len(gpus)\n",
    "print(\"GPU nodes found: \" + str(num_gpus),flush=True)\n",
    "for i in range(num_gpus):\n",
    "    print('Avaialble gpu:',str(gpus[i]),flush=True)\n",
    "\n",
    "\n",
    "## Finding how many CPUs are available\n",
    "cpus = [x.name for x in device_lib.list_local_devices() if x.device_type == 'CPU']\n",
    "num_cpus = len(cpus)\n",
    "print(\"CPU nodes found: \" + str(num_cpus),flush=True)\n",
    "for i in range(num_cpus):\n",
    "    print('Avaialble cpu:',str(cpus[i]),flush=True)\n",
    "\n",
    "\n",
    "## Defining placeholders in tf for images and targets\n",
    "x_image = tf.placeholder(tf.float32, [None, 16,height,width,channel]) \n",
    "y_true = tf.placeholder(tf.float32, [None, nb_classes])\n",
    "y_true_cls = tf.placeholder(tf.int64, [None])\n",
    "\n",
    "print('Finished obtaining gpu details and place holders',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished defining special functions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:392: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(64, (3, 3, 3), activation=\"relu\", name=\"conv1\", input_shape=(16, 112, ..., padding=\"same\")`\n",
      "  input_shape=input_shape))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:394: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(1, 2, 2), strides=(1, 2, 2), name=\"pool1\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool1'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:397: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(128, (3, 3, 3), activation=\"relu\", name=\"conv2\", padding=\"same\")`\n",
      "  border_mode='same', name='conv2'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:399: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool2\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool2'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:402: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv3a'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:404: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(256, (3, 3, 3), activation=\"relu\", name=\"conv3b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv3b'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:406: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool3\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool3'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:409: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv4a'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:411: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv4b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv4b'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:413: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool4\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool4'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:416: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv5a\", padding=\"same\")`\n",
      "  border_mode='same', name='conv5a'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:418: UserWarning: Update your `Conv3D` call to the Keras 2 API: `Conv3D(512, (3, 3, 3), activation=\"relu\", name=\"conv5b\", padding=\"same\")`\n",
      "  border_mode='same', name='conv5b'))\n",
      "/home/ufaserv1_f/cnlp/Seeing_to_Learn/Observation-Learning/Stage_5_New_loss_function/modelling.py:421: UserWarning: Update your `MaxPooling3D` call to the Keras 2 API: `MaxPooling3D(pool_size=(2, 2, 2), strides=(2, 2, 2), name=\"pool5\", padding=\"valid\")`\n",
      "  border_mode='valid', name='pool5'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1 (Conv3D)               (None, 16, 112, 112, 64)  5248      \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling3D)         (None, 16, 56, 56, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv2 (Conv3D)               (None, 16, 56, 56, 128)   221312    \n",
      "_________________________________________________________________\n",
      "pool2 (MaxPooling3D)         (None, 8, 28, 28, 128)    0         \n",
      "_________________________________________________________________\n",
      "conv3a (Conv3D)              (None, 8, 28, 28, 256)    884992    \n",
      "_________________________________________________________________\n",
      "conv3b (Conv3D)              (None, 8, 28, 28, 256)    1769728   \n",
      "_________________________________________________________________\n",
      "pool3 (MaxPooling3D)         (None, 4, 14, 14, 256)    0         \n",
      "_________________________________________________________________\n",
      "conv4a (Conv3D)              (None, 4, 14, 14, 512)    3539456   \n",
      "_________________________________________________________________\n",
      "conv4b (Conv3D)              (None, 4, 14, 14, 512)    7078400   \n",
      "_________________________________________________________________\n",
      "pool4 (MaxPooling3D)         (None, 2, 7, 7, 512)      0         \n",
      "_________________________________________________________________\n",
      "conv5a (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "conv5b (Conv3D)              (None, 2, 7, 7, 512)      7078400   \n",
      "_________________________________________________________________\n",
      "zeropad5 (ZeroPadding3D)     (None, 2, 8, 8, 512)      0         \n",
      "_________________________________________________________________\n",
      "pool5 (MaxPooling3D)         (None, 1, 4, 4, 512)      0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "fc6 (Dense)                  (None, 4096)              33558528  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc7 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "fc8 (Dense)                  (None, 101)               413797    \n",
      "=================================================================\n",
      "Total params: 78,409,573\n",
      "Trainable params: 78,409,573\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Tensor(\"sequential_1/fc8/BiasAdd:0\", shape=(?, 101), dtype=float32, device=/device:GPU:0)\n"
     ]
    }
   ],
   "source": [
    "#### Creating the model and defining the function to parallelise data\n",
    "# Define the network in a model function, to make parallelisation across GPUs easier.\n",
    "def model(x_image_, y_true_):\n",
    "    ''' Expecting the following parameters, in batches:\n",
    "        x_image_ - x_image batch\n",
    "        y_true_ - y_true batch\n",
    "    '''\n",
    "\n",
    "    model_keras = md.C3D_ucf101_training_model_tf(summary=True)\n",
    "    #model_keras = modelC3D(cluster_length, height, width, channel,summary=False, load_weights=True)\n",
    "    out=model_keras(x_image_)\n",
    "    print(out,flush=True)\n",
    "    \n",
    "    y_pred = tf.nn.softmax(out)\n",
    "    y_pred_cls = tf.argmax(out, dimension=1)\n",
    "    loss=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y_true_,logits=out))\n",
    "    \n",
    "    # Outputs to be returned to CPU\n",
    "    return y_pred, y_pred_cls, loss\n",
    "\n",
    "\n",
    "def make_parallel(fn, **kwargs):\n",
    "    in_splits = {}\n",
    "    for k, v in kwargs.items():\n",
    "        in_splits[k] = tf.split(v, num_gpus)\n",
    "    # An array for every aggregated output\n",
    "    y_pred_split, y_pred_cls_split, cost_split = [], [], []\n",
    "    for i in range(num_gpus):\n",
    "        with tf.device(tf.DeviceSpec(device_type=\"GPU\", device_index=i)):\n",
    "            with tf.variable_scope(tf.get_variable_scope(), reuse=i > 0):\n",
    "                y_pred_, y_pred_cls_, cost_,  = fn(**{k : v[i] for k, v in in_splits.items()})\n",
    "                # Adding the output from each device.\n",
    "                y_pred_split.append(y_pred_)\n",
    "                y_pred_cls_split.append(y_pred_cls_)\n",
    "                cost_split.append(cost_)\n",
    "                #fv_split.append(fv_)\n",
    "    # Aggregating and returning outputs. tf.concat for multi-dimensional arrays; tf.stack if single values.\n",
    "    return tf.concat(y_pred_split, axis=0), tf.concat(y_pred_cls_split, axis=0),tf.stack(cost_split, axis=0)\n",
    "\n",
    "print('Finished defining special functions',flush=True)\n",
    "  \n",
    "if num_gpus > 0:\n",
    "    # There is significant latency for CPU<->GPU copying of shared variables.\n",
    "    # We want the best balance between speedup and minimal latency.\n",
    "    y_pred, y_pred_cls, cost = make_parallel(model, x_image_=x_image, y_true_=y_true)\n",
    "else:\n",
    "    # CPU-only version\n",
    "    y_pred, y_pred_cls, cost = model(x_image_=x_image, y_true_=y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Optimisation calculated on CPU on aggregated results.\n",
    "# NEED the colocate_gradients_with_ops flag TRUE to get the gradient ops to run on same device as original op!\n",
    "optimizer = tf.train.AdagradOptimizer(learning_rate=2e-4).minimize(cost, colocate_gradients_with_ops=True)\n",
    "correct_prediction = tf.equal(y_pred_cls, y_true_cls)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "print('Miscellenious items finished..!!',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Training & testing\n",
    "def testing(iterations,loops):\n",
    "    #print(test_images.shape)\n",
    "    #print(test_labels_cls)\n",
    "    test_score=0\n",
    "    for j in range(int(memory_batch_size_test/batch_size_test)-1):\n",
    "        test_score_ = sess.run([accuracy], feed_dict={x_image:test_images[(batch_size_test*j):(batch_size_test*(j+1))],y_true_cls:test_labels_cls[(batch_size_test*j):(batch_size_test*(j+1))],K.learning_phase(): 0 })\n",
    "        #print('returned value',test_score_)\n",
    "        test_score=test_score+sum(test_score_)\n",
    "    print('Test accuracy after iteration:',iterations,',loop:',loops,'is:',test_score/(j+1),flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Loading Testing data\n",
    "test_images, test_labels_cls, next_batch_start, _ = ucf.read_vid_and_label('./UCF101_data_preparation/test.list',memory_batch_size_test,-1,16,112,normalisation=True)\n",
    "test_labels=keras.utils.to_categorical(test_labels_cls, num_classes=nb_classes)\n",
    "print('testing data loaded',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "\n",
    "testing(0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Start the session with logging placement.\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "sess.run(init_op)\n",
    "saver = tf.train.Saver() \n",
    "print ('started the session...!!',flush=True)\n",
    "\n",
    "## Loading Training data\n",
    "start_time = time.time()\n",
    "train_images, train_labels_cls, next_batch_start, _ = ucf. read_vid_and_label('./UCF101_data_preparation/train.list',memory_batch_size_train,-1,cluster_length,112,normalisation=True)\n",
    "end_time = time.time()\n",
    "time_dif = end_time - start_time\n",
    "print(\"Time usage for loading training dataset: \" + str(timedelta(seconds=int(round(time_dif)))),flush=True)\n",
    "train_labels=keras.utils.to_categorical(train_labels_cls, num_classes=nb_classes)\n",
    "\n",
    "## Loading Testing data\n",
    "test_images, test_labels_cls, next_batch_start, _ = ucf.read_vid_and_label('./UCF101_data_preparation/test.list',memory_batch_size_test,-1,16,112,normalisation=True)\n",
    "test_labels=keras.utils.to_categorical(test_labels_cls, num_classes=nb_classes)\n",
    "print('testing data loaded',flush=True)\n",
    "\n",
    "for i in range(0,(iterations*10)):\n",
    "    print('started iteration:',i,flush=True)\n",
    "    \n",
    "    for j in range (int(memory_batch_size_train/batch_size)-1):    \n",
    "        print ('This is epoch:',j,'going to be trained',flush=True)\n",
    "        output_value = sess.run([optimizer], feed_dict={x_image:train_images[(batch_size*j):(batch_size*(j+1))],y_true:train_labels[(batch_size*j):(batch_size*(j+1))],K.learning_phase(): 1 })   \n",
    "        print ('This is epoch:',j,'trained',flush=True)\n",
    "        if (int(j%300)==0):\n",
    "            testing(i,j)\n",
    "            #print('tested')\n",
    "    testing(i,j)\n",
    "    saver.save(sess, os.path.join(LOG_DIR, \"activity_model_1.ckpt\"), global_step=custom_global_step)\n",
    "    custom_global_step=custom_global_step+1   \n",
    "    print('Model saved after iteration:',i,flush=True)\n",
    "\n",
    "\n",
    "sess.close()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
